{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DsCRYgtBh03oqgQrF6cLXuGiaDjCfay0",
      "authorship_tag": "ABX9TyN28XXK7QYtjiu0Kfs2OYZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogbidaniel/CodeLibrary/blob/main/Recurrent_Neural_Network_for_Breast_Cancer_Recurrence_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Outline\n",
        "\n",
        "1. Setup Notebook\n",
        "2. Load Data\n",
        "3. Define Model in Pytorch\n",
        "4. Train Model\n",
        "5. Evaluate"
      ],
      "metadata": {
        "id": "7rfxY6WKTueY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Notebook"
      ],
      "metadata": {
        "id": "kcuRBHUBTtbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your google drive to the notebook runtime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "9yg6w3JEeSyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rezhT-vrTczO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset into the Notebook using Pandas"
      ],
      "metadata": {
        "id": "bK2DSSD-envt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load the gene data into a 'data' dataframe from a placeholder google drive file path\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/gene_expression.csv')\n"
      ],
      "metadata": {
        "id": "SJBH2-WJfX4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the data\n",
        "Training `80%` Testing `20%`[link text](https://)"
      ],
      "metadata": {
        "id": "hYpIF-j2xDE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume df is your DataFrame and has already been loaded into the notebook\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['DFS_STATUS'])\n",
        "y = data['DFS_STATUS']\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "_DWlA1M4ya-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Dataset and Dataloader class"
      ],
      "metadata": {
        "id": "jlBB4fPZ2Huq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BreastCancerDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ],
      "metadata": {
        "id": "lUW9fl6_2aXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BreastCancerDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = BreastCancerDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "f2uPB5kv2cWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Recurrent Neural Network Model"
      ],
      "metadata": {
        "id": "89Fd4ssF2qWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "input_size = X_train.shape[1]  # Number of features\n",
        "hidden_size = 128  # Number of hidden units in RNN\n",
        "num_layers = 2  # Number of RNN layers\n",
        "output_size = 1  # Binary classification\n",
        "\n",
        "model = RNNModel(input_size, hidden_size, num_layers, output_size)"
      ],
      "metadata": {
        "id": "iT0zA1tc22Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "JE-MpGll2-H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "fyMtaDLN3Cog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Reshape input tensor to have the shape (batch_size, sequence_length, input_size)\n",
        "        X_batch = X_batch.view(X_batch.size(0), 1, -1)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs.squeeze(), y_batch)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "rUfFKD6C3Fuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "QXjD4JS53InP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        # Reshape input tensor to have the shape (batch_size, sequence_length, input_size)\n",
        "        X_batch = X_batch.view(X_batch.size(0), 1, -1)\n",
        "\n",
        "        # Predict\n",
        "        outputs = model(X_batch)\n",
        "        predictions = torch.round(torch.sigmoid(outputs.squeeze()))\n",
        "        y_pred.extend(predictions.tolist())\n",
        "        y_true.extend(y_batch.tolist())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_pred = np.array(y_pred)\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (y_pred == y_true).mean()\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "jcrM4pS43MsN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}